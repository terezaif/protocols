{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/filecommits.csv\"\n",
    "protocols = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "protocols[\"ts\"] = protocols.date_commit.apply(lambda x: pd.datetime.fromtimestamp(x).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(s):\n",
    "    s = re.sub('[^\\s]*.com[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*www.[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*.co.uk[^\\s]*', \"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols['clean_text'] = protocols['text'].map(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenising with Spacy\n",
    "protocols['tokens_clean_text'] = protocols['clean_text'].map(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols['sentences_clean_text'] = protocols['tokens_clean_text'].apply(lambda toks: list(toks.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0 Day  True False False Xxx False\n"
     ]
    }
   ],
   "source": [
    "for token in protocols['tokens_clean_text'][0]:\n",
    "    print (token, token.idx, token.text_with_ws,token.is_alpha, token.is_punct, token.is_space,token.shape_, token.is_stop)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#things we want to do:\n",
    "\n",
    "# Entities and Sentiment? :)\n",
    "\n",
    "\n",
    "# get number of tokens per document\n",
    "protocols[\"token_count\"] = protocols['tokens_clean_text'].map(len)\n",
    "# get number of sentences\n",
    "protocols[\"sentence_count\"] = protocols['sentences_clean_text'].map(len)\n",
    "\n",
    "# get number of words that are not punctions and so on\n",
    "protocols[\"content_words_alpha\"] = protocols['tokens_clean_text'].apply(lambda toks: [token for token in toks if token.is_alpha is True and token.is_stop is False and token.is_punct is False])\n",
    "\n",
    "protocols[\"content_word_count\"] = protocols['content_words_alpha'].map(len)\n",
    "\n",
    "protocols[\"content_words_alpha_len\"] = protocols[\"content_words_alpha\"].apply(lambda words: [len(word) for word in words if len(word) > 2])\n",
    "# get avg word length\n",
    "protocols[\"avg_word_len\"] = protocols[\"content_words_alpha_len\"].apply(lambda lens: sum(lens)/len(lens))\n",
    "#median word length\n",
    "protocols[\"median_word_len\"] = protocols[\"content_words_alpha_len\"].apply(lambda lens: sorted(lens)[len(lens)//2 - 1])\n",
    "\n",
    "# get median word length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the cardinality of docs per person\n",
    "#sort by date/filenam\n",
    "protocols = protocols.sort_values([\"ts\", \"filename\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols['author_day'] = protocols.groupby('author').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>author_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Erin Robinson</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bonnie Brown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Timothy Stevens</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Larry Sanders</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Zachary Brooks</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>William Rodriguez</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Amy Williams</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Bonnie Williams</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Nicole Johnson</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Thomas Hansen</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Jennifer Montgomery</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Jacob Phillips</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Charles Christensen</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Bonnie Brown</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Erin Robinson</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Timothy Stevens</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Larry Sanders</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Zachary Brooks</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Amy Williams</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>William Rodriguez</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Bonnie Williams</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Nicole Johnson</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Thomas Hansen</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Charles Christensen</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Jacob Phillips</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Jennifer Montgomery</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Erin Robinson</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Bonnie Brown</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Timothy Stevens</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Larry Sanders</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Zachary Brooks</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>William Rodriguez</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Amy Williams</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Bonnie Williams</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Nicole Johnson</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Jacob Phillips</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Charles Christensen</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Thomas Hansen</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Jennifer Montgomery</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                 author  author_day\n0         Erin Robinson           0\n1          Bonnie Brown           0\n2       Timothy Stevens           0\n3         Larry Sanders           0\n4        Zachary Brooks           0\n5     William Rodriguez           0\n6          Amy Williams           0\n7       Bonnie Williams           0\n8        Nicole Johnson           0\n9         Thomas Hansen           0\n10  Jennifer Montgomery           0\n11       Jacob Phillips           0\n12  Charles Christensen           0\n13         Bonnie Brown           1\n14        Erin Robinson           1\n15      Timothy Stevens           1\n16        Larry Sanders           1\n17       Zachary Brooks           1\n18         Amy Williams           1\n19    William Rodriguez           1\n20      Bonnie Williams           1\n21       Nicole Johnson           1\n22        Thomas Hansen           1\n23  Charles Christensen           1\n24       Jacob Phillips           1\n25  Jennifer Montgomery           1\n26        Erin Robinson           2\n27         Bonnie Brown           2\n28      Timothy Stevens           2\n29        Larry Sanders           2\n30       Zachary Brooks           2\n31    William Rodriguez           2\n32         Amy Williams           2\n33      Bonnie Williams           2\n34       Nicole Johnson           2\n35       Jacob Phillips           2\n36  Charles Christensen           2\n37        Thomas Hansen           2\n38  Jennifer Montgomery           2"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols[[\"author\", \"author_day\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39 entries, 0 to 38\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   filename                 39 non-null     object \n",
      " 1   author                   39 non-null     object \n",
      " 2   date_commit              39 non-null     int64  \n",
      " 3   text                     39 non-null     object \n",
      " 4   ts                       39 non-null     object \n",
      " 5   clean_text               39 non-null     object \n",
      " 6   tokens_clean_text        39 non-null     object \n",
      " 7   sentences_clean_text     39 non-null     object \n",
      " 8   token_count              39 non-null     int64  \n",
      " 9   sentence_count           39 non-null     int64  \n",
      " 10  content_words_alpha      39 non-null     object \n",
      " 11  content_word_count       39 non-null     int64  \n",
      " 12  content_words_alpha_len  39 non-null     object \n",
      " 13  avg_word_len             39 non-null     float64\n",
      " 14  median_word_len          39 non-null     int64  \n",
      " 15  author_day               39 non-null     int64  \n",
      "dtypes: float64(1), int64(6), object(9)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "protocols.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39 entries, 0 to 38\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   author_day       39 non-null     int64 \n",
      " 1   author           39 non-null     object\n",
      " 2   sentence_count   39 non-null     int64 \n",
      " 3   median_word_len  39 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "source = protocols[[\"author_day\", \"author\", \"sentence_count\", \"median_word_len\"]]\n",
    "\n",
    "source['author_day'] = source['author_day'] + 1\n",
    "source.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "author_day                                                       39\nauthor            Erin RobinsonBonnie BrownTimothy StevensLarry ...\nsentence_count                                                 2441\ntoken_count                                                   31737\ndtype: object"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols[[\"author_day\", \"author\", \"sentence_count\", \"token_count\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-6dbb719758aa439897ee0d64b8a4965f\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-6dbb719758aa439897ee0d64b8a4965f\") {\n      outputDiv = document.getElementById(\"altair-viz-6dbb719758aa439897ee0d64b8a4965f\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"font\": \"OpenSans\", \"legend\": {\"labelFontSize\": 15, \"symbolSize\": 100}, \"title\": {\"color\": \"#000000\", \"fontSize\": 20}}, \"data\": {\"name\": \"data-1f11f1afbe81fb9ac19e8d03aefefe4c\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.8, \"stroke\": \"black\", \"strokeWidth\": 1}, \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"median_word_len\", \"legend\": {\"title\": \"median word length\"}, \"scale\": {\"scheme\": \"lightmulti\"}}, \"size\": {\"type\": \"quantitative\", \"field\": \"sentence_count\", \"legend\": {\"title\": \"sentence count\"}, \"scale\": {\"range\": [0, 3000]}}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"median_word_len\", \"title\": \"Word len\"}, {\"type\": \"quantitative\", \"field\": \"sentence_count\", \"title\": \"Sentence count\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"tickMinStep\": 1}, \"field\": \"author_day\", \"scale\": {\"domain\": [0.5, 3.5]}, \"title\": \"Protocol count\"}, \"y\": {\"type\": \"nominal\", \"axis\": {\"grid\": true}, \"field\": \"author\", \"title\": null}}, \"height\": 400, \"title\": \"Sentences per protocol by student\", \"width\": 550, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-1f11f1afbe81fb9ac19e8d03aefefe4c\": [{\"author_day\": 1, \"author\": \"Erin Robinson\", \"sentence_count\": 64, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Bonnie Brown\", \"sentence_count\": 69, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Timothy Stevens\", \"sentence_count\": 66, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Larry Sanders\", \"sentence_count\": 108, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Zachary Brooks\", \"sentence_count\": 56, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"William Rodriguez\", \"sentence_count\": 18, \"median_word_len\": 7}, {\"author_day\": 1, \"author\": \"Amy Williams\", \"sentence_count\": 104, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Bonnie Williams\", \"sentence_count\": 135, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Nicole Johnson\", \"sentence_count\": 80, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Thomas Hansen\", \"sentence_count\": 85, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 62, \"median_word_len\": 7}, {\"author_day\": 1, \"author\": \"Jacob Phillips\", \"sentence_count\": 36, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Charles Christensen\", \"sentence_count\": 37, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Bonnie Brown\", \"sentence_count\": 70, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Erin Robinson\", \"sentence_count\": 52, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Timothy Stevens\", \"sentence_count\": 68, \"median_word_len\": 7}, {\"author_day\": 2, \"author\": \"Larry Sanders\", \"sentence_count\": 114, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Zachary Brooks\", \"sentence_count\": 68, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Amy Williams\", \"sentence_count\": 51, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"William Rodriguez\", \"sentence_count\": 72, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Bonnie Williams\", \"sentence_count\": 50, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Nicole Johnson\", \"sentence_count\": 137, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Thomas Hansen\", \"sentence_count\": 27, \"median_word_len\": 7}, {\"author_day\": 2, \"author\": \"Charles Christensen\", \"sentence_count\": 26, \"median_word_len\": 5}, {\"author_day\": 2, \"author\": \"Jacob Phillips\", \"sentence_count\": 19, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 60, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Erin Robinson\", \"sentence_count\": 25, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Bonnie Brown\", \"sentence_count\": 43, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Timothy Stevens\", \"sentence_count\": 40, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Larry Sanders\", \"sentence_count\": 36, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Zachary Brooks\", \"sentence_count\": 82, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"William Rodriguez\", \"sentence_count\": 50, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Amy Williams\", \"sentence_count\": 14, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Bonnie Williams\", \"sentence_count\": 16, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Nicole Johnson\", \"sentence_count\": 110, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Jacob Phillips\", \"sentence_count\": 98, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Charles Christensen\", \"sentence_count\": 63, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Thomas Hansen\", \"sentence_count\": 47, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 83, \"median_word_len\": 6}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(source).mark_circle(\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    alt.X('author_day:Q', scale=alt.Scale(domain=[0.5, 3.5]),axis=alt.Axis(grid=False,tickMinStep=1), title='Protocol count'),\n",
    "    alt.Y('author:N',axis=alt.Axis(grid=True),  title=\" \"),\n",
    "    alt.Size('sentence_count',\n",
    "        scale=alt.Scale(range=[0, 3000]),\n",
    "        legend=alt.Legend(title='sentence count')\n",
    "    ),\n",
    "   color = alt.Color('median_word_len', legend=alt.Legend(title='median word length'),  scale=alt.Scale(scheme='lightmulti')),\n",
    "   tooltip=[\n",
    "        alt.Tooltip('median_word_len:Q', title='Word len'),\n",
    "        alt.Tooltip('sentence_count:Q', title='Sentence count')\n",
    "    ]\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ").properties(height=400, width=550, title='Sentences per protocol by student').configure(font='OpenSans').configure_legend(\n",
    "    symbolSize=150,\n",
    "    labelFontSize=15,\n",
    "    titleFontSize=15,\n",
    "    padding = 40\n",
    ").configure_title(\n",
    "    fontSize=20,\n",
    "    color='#000000',\n",
    ").configure_legend(\n",
    "    symbolSize=100,\n",
    "    labelFontSize=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-93b9494e56894b5b9ad030b3a25a927a\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-93b9494e56894b5b9ad030b3a25a927a\") {\n      outputDiv = document.getElementById(\"altair-viz-93b9494e56894b5b9ad030b3a25a927a\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-1f11f1afbe81fb9ac19e8d03aefefe4c\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.8, \"stroke\": \"black\", \"strokeWidth\": 1}, \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"median_word_len\"}, \"size\": {\"type\": \"quantitative\", \"field\": \"sentence_count\", \"legend\": {\"title\": \"sentence count\"}, \"scale\": {\"range\": [0, 3000]}}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"median_word_len\", \"title\": \"Word len\"}, {\"type\": \"quantitative\", \"field\": \"sentence_count\", \"title\": \"Sentence count\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false}, \"field\": \"author_day\", \"scale\": {\"domain\": [0, 4]}}, \"y\": {\"type\": \"nominal\", \"axis\": {\"grid\": true}, \"field\": \"author\"}}, \"height\": 500, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-1f11f1afbe81fb9ac19e8d03aefefe4c\": [{\"author_day\": 1, \"author\": \"Erin Robinson\", \"sentence_count\": 64, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Bonnie Brown\", \"sentence_count\": 69, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Timothy Stevens\", \"sentence_count\": 66, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Larry Sanders\", \"sentence_count\": 108, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Zachary Brooks\", \"sentence_count\": 56, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"William Rodriguez\", \"sentence_count\": 18, \"median_word_len\": 7}, {\"author_day\": 1, \"author\": \"Amy Williams\", \"sentence_count\": 104, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Bonnie Williams\", \"sentence_count\": 135, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Nicole Johnson\", \"sentence_count\": 80, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Thomas Hansen\", \"sentence_count\": 85, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 62, \"median_word_len\": 7}, {\"author_day\": 1, \"author\": \"Jacob Phillips\", \"sentence_count\": 36, \"median_word_len\": 6}, {\"author_day\": 1, \"author\": \"Charles Christensen\", \"sentence_count\": 37, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Bonnie Brown\", \"sentence_count\": 70, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Erin Robinson\", \"sentence_count\": 52, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Timothy Stevens\", \"sentence_count\": 68, \"median_word_len\": 7}, {\"author_day\": 2, \"author\": \"Larry Sanders\", \"sentence_count\": 114, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Zachary Brooks\", \"sentence_count\": 68, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Amy Williams\", \"sentence_count\": 51, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"William Rodriguez\", \"sentence_count\": 72, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Bonnie Williams\", \"sentence_count\": 50, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Nicole Johnson\", \"sentence_count\": 137, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Thomas Hansen\", \"sentence_count\": 27, \"median_word_len\": 7}, {\"author_day\": 2, \"author\": \"Charles Christensen\", \"sentence_count\": 26, \"median_word_len\": 5}, {\"author_day\": 2, \"author\": \"Jacob Phillips\", \"sentence_count\": 19, \"median_word_len\": 6}, {\"author_day\": 2, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 60, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Erin Robinson\", \"sentence_count\": 25, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Bonnie Brown\", \"sentence_count\": 43, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Timothy Stevens\", \"sentence_count\": 40, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Larry Sanders\", \"sentence_count\": 36, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Zachary Brooks\", \"sentence_count\": 82, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"William Rodriguez\", \"sentence_count\": 50, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Amy Williams\", \"sentence_count\": 14, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Bonnie Williams\", \"sentence_count\": 16, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Nicole Johnson\", \"sentence_count\": 110, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Jacob Phillips\", \"sentence_count\": 98, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Charles Christensen\", \"sentence_count\": 63, \"median_word_len\": 7}, {\"author_day\": 3, \"author\": \"Thomas Hansen\", \"sentence_count\": 47, \"median_word_len\": 6}, {\"author_day\": 3, \"author\": \"Jennifer Montgomery\", \"sentence_count\": 83, \"median_word_len\": 6}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "color = alt.Color('author', scale=scale)\n",
    "\n",
    "bubbles = alt.Chart().mark_circle(\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    alt.X('author_day', scale=alt.Scale(domain=[0, 4]),axis=alt.Axis(grid=False) ),\n",
    "    alt.Y('median_word_len',axis=alt.Axis(grid=True)),\n",
    "    alt.Size('sentence_count',\n",
    "        scale=alt.Scale(range=[0, 3000]),\n",
    "        legend=alt.Legend(title='sentence count')\n",
    "    ),\n",
    "   color = alt.condition(brush, color, alt.value('lightgray')),\n",
    "   tooltip=[\n",
    "        alt.Tooltip('median_word_len:Q', title='Word len'),\n",
    "        alt.Tooltip('sentence_count:Q', title='Sentence count')\n",
    "    ]\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "\n",
    "# Bottom panel is a bar chart of weather type\n",
    "bars = alt.Chart().mark_bar().encode(\n",
    "    x='count()',\n",
    "    y='author',\n",
    "    color=alt.condition(click, color, alt.value('lightgray')),\n",
    ").transform_filter(\n",
    "    brush\n",
    ").properties(\n",
    "    width=550,\n",
    ").add_selection(\n",
    "    click\n",
    ")\n",
    "\n",
    "\n",
    "alt.vconcat(\n",
    "    bubbles,\n",
    "    bars,\n",
    "    data=source,\n",
    "    title=\"neuefische DS-4 protocols 2020\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "source = data.disasters.url\n",
    "\n",
    "alt.Chart(source).mark_circle(\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    alt.X('Year:O', axis=alt.Axis(labelAngle=0)),\n",
    "    alt.Y('Entity:N'),\n",
    "    alt.Size('Deaths:Q',\n",
    "        scale=alt.Scale(range=[0, 4000]),\n",
    "        legend=alt.Legend(title='Annual Global Deaths')\n",
    "    ),\n",
    "    alt.Color('Entity:N', legend=None)\n",
    ").properties(\n",
    "    width=450,\n",
    "    height=320\n",
    ").transform_filter(\n",
    "    alt.datum.Entity != 'All natural disasters'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}